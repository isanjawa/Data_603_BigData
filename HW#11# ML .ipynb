{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "DATA 603 â€“ Big Data Platforms\n",
    "\n",
    "Homework #11 ML + AWS\n",
    "\n",
    "Write a Spark ML-lib program to predict flight delays for certain airline UMAIR. UMAIR operates throughout the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random data for flights of size about 100 rows.\n",
    "\n",
    "import random\n",
    "from datetime import date, time\n",
    "import csv\n",
    "\n",
    "list_airport_code=['BWI', 'CAE', 'EEN', 'PHL', 'LAX', 'JFK', 'MIA']\n",
    "\n",
    "# random Day generator\n",
    "def generate_date():\n",
    "\n",
    "    start_dt = date.today().replace(day=1, month=1, year=2019).toordinal()\n",
    "    end_dt = date.today().toordinal()\n",
    "    random_day = date.fromordinal(random.randint(start_dt, end_dt))\n",
    "    return random_day\n",
    "\n",
    "# random Time generator\n",
    "def generate_time():\n",
    "    hours = random.randint(3,23)\n",
    "    minutes= random.randint(0,59)\n",
    "    \n",
    "    t1 = time(hours-(random.randint(0,2)), minutes) #flight schedule land time\n",
    "    t2 = time(hours, minutes) # flight actual land time\n",
    "    \n",
    "    format = \"%H:%M\"\n",
    "    #format datetime using strftime()\n",
    "    start_time = t1.strftime(format)\n",
    "    end_time= t2.strftime(format)\n",
    "    \n",
    "    return [start_time, end_time]\n",
    "\n",
    " \n",
    "#Final function\n",
    "def createFakeData(name_of_file, number_of_rows):\n",
    "    with open (name_of_file, 'w', newline='') as file:\n",
    "        writeData = csv.writer(file)\n",
    "\n",
    "        #The headers\n",
    "        writeData.writerow(['Flight No', \n",
    "                            'Date', \n",
    "                            'Time',\n",
    "                            'Actual Date',\n",
    "                            'Actual Time', \n",
    "                            'Airports'])\n",
    "        \n",
    "        for i in range(1,number_of_rows):\n",
    "            \n",
    "            day=generate_date()\n",
    "            time=generate_time()\n",
    "            aiport_codes = random.sample(list_airport_code, 2)\n",
    "            \n",
    "            writeData.writerow(['UM-'+ str(random.randint(400,799)+i),\n",
    "                                 day, \n",
    "                                 time[0] ,\n",
    "                                 day,\n",
    "                                 time[1],\n",
    "                                 aiport_codes[0]+ '-' + aiport_codes[1]\n",
    "                               ])\n",
    "                                \n",
    "                                \n",
    "    #print('You created a CSV file: ' + str(name_of_file) + ' with ' + str(number_of_rows) + ' rows.' )\n",
    "            \n",
    "createFakeData('FlightData.csv', 101)                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/kharpann/perform-linear-regression-on-big-data-using-python-spark-and-mllib-b1204769547e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('flights delay').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+-----------+-----------+--------+\n",
      "|Flight No|      Date| Time|Actual Date|Actual Time|Airports|\n",
      "+---------+----------+-----+-----------+-----------+--------+\n",
      "|   UM-754|2019-02-08|02:01| 2019-02-08|      04:01| CAE-JFK|\n",
      "|   UM-784|2019-04-17|13:32| 2019-04-17|      15:32| EEN-JFK|\n",
      "|   UM-778|2019-06-05|03:48| 2019-06-05|      04:48| JFK-LAX|\n",
      "|   UM-616|2019-04-03|07:31| 2019-04-03|      07:31| MIA-LAX|\n",
      "|   UM-793|2019-02-10|14:12| 2019-02-10|      14:12| MIA-JFK|\n",
      "+---------+----------+-----+-----------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "df1 = spark.read.csv(\"FlightData.csv\", header='true', inferSchema='false')\n",
    "#spark.read.format(\"csv\").load(\"FlightData.csv\")\n",
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Flight No: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Actual Date: string (nullable = true)\n",
      " |-- Actual Time: string (nullable = true)\n",
      " |-- Airports: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+-----------+-----------+--------+\n",
      "|Flight No|      Date| Time|Actual Date|Actual Time|Airports|\n",
      "+---------+----------+-----+-----------+-----------+--------+\n",
      "|   UM-743|2020-07-10|09:58| 2020-07-10|      11:58| MIA-LAX|\n",
      "|   UM-526|2020-06-21|14:21| 2020-06-21|      14:21| PHL-JFK|\n",
      "|   UM-641|2020-06-17|18:11| 2020-06-17|      19:11| JFK-BWI|\n",
      "|   UM-831|2020-06-16|19:50| 2020-06-16|      20:50| LAX-BWI|\n",
      "|   UM-883|2020-06-13|14:06| 2020-06-13|      14:06| CAE-BWI|\n",
      "+---------+----------+-----+-----------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the dataframe in descending- sort by a single colunm\n",
    "\n",
    "df2 = df1.orderBy('Date', ascending=False)\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Change columns type\n",
    "for d in df2.columns:\n",
    "    if d in [\"Date\", \"Actual Date\"]:\n",
    "    # add condition for the cols to be type cast\n",
    "       df2=df2.withColumn(d, df2[d].cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Flight No: string (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Actual Date: date (nullable = true)\n",
      " |-- Actual Time: string (nullable = true)\n",
      " |-- Airports: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define timedelta function (obtain delay duration in minutes)\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def time_delta(y,x): \n",
    "    from datetime import datetime\n",
    "    end = datetime.strptime(y, '%H:%M')\n",
    "    start = datetime.strptime(x, '%H:%M')\n",
    "    delta = (end-start).seconds\n",
    "    return delta\n",
    "\n",
    "# register as a UDF \n",
    "f = udf(time_delta, IntegerType())\n",
    "\n",
    "# Apply function\n",
    "df_new = df2.withColumn('Delay Duration', f(df2[\"Actual Time\"], df2[\"Time\"])/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+-----------+-----------+--------+--------------+\n",
      "|Flight No|      Date| Time|Actual Date|Actual Time|Airports|Delay Duration|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+\n",
      "|   UM-743|2020-07-10|09:58| 2020-07-10|      11:58| MIA-LAX|         120.0|\n",
      "|   UM-526|2020-06-21|14:21| 2020-06-21|      14:21| PHL-JFK|           0.0|\n",
      "|   UM-641|2020-06-17|18:11| 2020-06-17|      19:11| JFK-BWI|          60.0|\n",
      "|   UM-831|2020-06-16|19:50| 2020-06-16|      20:50| LAX-BWI|          60.0|\n",
      "|   UM-883|2020-06-13|14:06| 2020-06-13|      14:06| CAE-BWI|           0.0|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+-----------+--------+-----------------+\n",
      "|summary|Flight No| Time|Actual Time|Airports|   Delay Duration|\n",
      "+-------+---------+-----+-----------+--------+-----------------+\n",
      "|  count|      100|  100|        100|     100|              100|\n",
      "|   mean|     null| null|       null|    null|             51.6|\n",
      "| stddev|     null| null|       null|    null|50.46691085165696|\n",
      "|    min|   UM-426|01:57|      03:17| BWI-CAE|              0.0|\n",
      "|    max|   UM-883|23:25|      23:25| PHL-MIA|            120.0|\n",
      "+-------+---------+-----+-----------+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Flight No: string (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Actual Date: date (nullable = true)\n",
      " |-- Actual Time: string (nullable = true)\n",
      " |-- Airports: string (nullable = true)\n",
      " |-- Delay Duration: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use OneHotEncoder to encode my categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+\n",
      "|Flight No|      Date| Time|Actual Date|Actual Time|Airports|Delay Duration|AirportsIndex|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+\n",
      "|   UM-743|2020-07-10|09:58| 2020-07-10|      11:58| MIA-LAX|         120.0|          6.0|\n",
      "|   UM-526|2020-06-21|14:21| 2020-06-21|      14:21| PHL-JFK|           0.0|         19.0|\n",
      "|   UM-641|2020-06-17|18:11| 2020-06-17|      19:11| JFK-BWI|          60.0|         21.0|\n",
      "|   UM-831|2020-06-16|19:50| 2020-06-16|      20:50| LAX-BWI|          60.0|         23.0|\n",
      "|   UM-883|2020-06-13|14:06| 2020-06-13|      14:06| CAE-BWI|           0.0|         20.0|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Category Indexing with StringIndexer\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol = \"Airports\", outputCol = \"Airports\"+ 'Index')\n",
    "df_new= stringIndexer.fit(df_new).transform(df_new)\n",
    "#indexer.show(5) \n",
    "\n",
    "# stringIndexer = StringIndexer(inputCol = \"Destination\", outputCol = \"Destination\"+ 'Index')\n",
    "# df_new= stringIndexer.fit(df_new).transform(df_new)\n",
    "df_new.show(5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+-------------------+\n",
      "|Flight No|      Date| Time|Actual Date|Actual Time|Airports|Delay Duration|AirportsIndex|Delay DurationIndex|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+-------------------+\n",
      "|   UM-743|2020-07-10|09:58| 2020-07-10|      11:58| MIA-LAX|         120.0|          6.0|                1.0|\n",
      "|   UM-526|2020-06-21|14:21| 2020-06-21|      14:21| PHL-JFK|           0.0|         19.0|                0.0|\n",
      "|   UM-641|2020-06-17|18:11| 2020-06-17|      19:11| JFK-BWI|          60.0|         21.0|                2.0|\n",
      "|   UM-831|2020-06-16|19:50| 2020-06-16|      20:50| LAX-BWI|          60.0|         23.0|                2.0|\n",
      "|   UM-883|2020-06-13|14:06| 2020-06-13|      14:06| CAE-BWI|           0.0|         20.0|                0.0|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the dependent variable(Delay Duration) into dependent variable indices using the StringIndexer\n",
    "dependent_stringIndexer = StringIndexer(inputCol = \"Delay Duration\", outputCol = \"Delay Duration\"+ 'Index')\n",
    "df_new = dependent_stringIndexer.fit(df_new).transform(df_new)\n",
    "df_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "\n",
    "# encoder = OneHotEncoderEstimator(inputCols=[\"DestinationIndex\"], outputCols=[\"DestinationVec\"], dropLast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = encoder.fit(df_new)\n",
    "# df_new= model.transform(df_new)\n",
    "# #df_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoderEstimator(inputCols=[\"AirportsIndex\"], outputCols=[\"AirportsVec\"])#, dropLast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+-------------------+---------------+\n",
      "|Flight No|      Date| Time|Actual Date|Actual Time|Airports|Delay Duration|AirportsIndex|Delay DurationIndex|    AirportsVec|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+-------------------+---------------+\n",
      "|   UM-743|2020-07-10|09:58| 2020-07-10|      11:58| MIA-LAX|         120.0|          6.0|                1.0| (39,[6],[1.0])|\n",
      "|   UM-526|2020-06-21|14:21| 2020-06-21|      14:21| PHL-JFK|           0.0|         19.0|                0.0|(39,[19],[1.0])|\n",
      "|   UM-641|2020-06-17|18:11| 2020-06-17|      19:11| JFK-BWI|          60.0|         21.0|                2.0|(39,[21],[1.0])|\n",
      "|   UM-831|2020-06-16|19:50| 2020-06-16|      20:50| LAX-BWI|          60.0|         23.0|                2.0|(39,[23],[1.0])|\n",
      "|   UM-883|2020-06-13|14:06| 2020-06-13|      14:06| CAE-BWI|           0.0|         20.0|                0.0|(39,[20],[1.0])|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+-------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = encoder.fit(df_new)\n",
    "df_new= model1.transform(df_new)\n",
    "df_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+-------------------+---------------+--------------------+\n",
      "|Flight No|      Date| Time|Actual Date|Actual Time|Airports|Delay Duration|AirportsIndex|Delay DurationIndex|    AirportsVec|Independent Features|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+-------------------+---------------+--------------------+\n",
      "|   UM-743|2020-07-10|09:58| 2020-07-10|      11:58| MIA-LAX|         120.0|          6.0|                1.0| (39,[6],[1.0])|      (39,[6],[1.0])|\n",
      "|   UM-526|2020-06-21|14:21| 2020-06-21|      14:21| PHL-JFK|           0.0|         19.0|                0.0|(39,[19],[1.0])|     (39,[19],[1.0])|\n",
      "|   UM-641|2020-06-17|18:11| 2020-06-17|      19:11| JFK-BWI|          60.0|         21.0|                2.0|(39,[21],[1.0])|     (39,[21],[1.0])|\n",
      "|   UM-831|2020-06-16|19:50| 2020-06-16|      20:50| LAX-BWI|          60.0|         23.0|                2.0|(39,[23],[1.0])|     (39,[23],[1.0])|\n",
      "|   UM-883|2020-06-13|14:06| 2020-06-13|      14:06| CAE-BWI|           0.0|         20.0|                0.0|(39,[20],[1.0])|     (39,[20],[1.0])|\n",
      "+---------+----------+-----+-----------+-----------+--------+--------------+-------------+-------------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform all features into a vector using VectorAssembler\n",
    "\n",
    "featureassembler = VectorAssembler().setInputCols([ \"AirportsVec\"]).setOutputCol(\"Independent Features\")\n",
    "output1 = featureassembler.transform(df_new)\n",
    "output1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " finalize_data = output1.select(\"Independent Features\",\"Delay Duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|Independent Features|Delay Duration|\n",
      "+--------------------+--------------+\n",
      "|      (39,[6],[1.0])|         120.0|\n",
      "|     (39,[19],[1.0])|           0.0|\n",
      "|     (39,[21],[1.0])|          60.0|\n",
      "|     (39,[23],[1.0])|          60.0|\n",
      "|     (39,[20],[1.0])|           0.0|\n",
      "|      (39,[9],[1.0])|         120.0|\n",
      "|      (39,[7],[1.0])|          60.0|\n",
      "|      (39,[3],[1.0])|          60.0|\n",
      "|      (39,[5],[1.0])|         120.0|\n",
      "|     (39,[22],[1.0])|           0.0|\n",
      "|     (39,[31],[1.0])|           0.0|\n",
      "|      (39,[5],[1.0])|          60.0|\n",
      "|      (39,[0],[1.0])|         120.0|\n",
      "|     (39,[18],[1.0])|           0.0|\n",
      "|     (39,[12],[1.0])|           0.0|\n",
      "|      (39,[1],[1.0])|         120.0|\n",
      "|     (39,[10],[1.0])|          60.0|\n",
      "|     (39,[14],[1.0])|         120.0|\n",
      "|     (39,[11],[1.0])|           0.0|\n",
      "|     (39,[33],[1.0])|         120.0|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalize_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 87\n",
      "Test Dataset Count: 13\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = finalize_data.randomSplit([0.9, 0.1], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(train_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reate an instance of our model using the given columns and also instantiate a prediction named column for our predictions\n",
    "lin_reg=LinearRegression(featuresCol='Independent Features',labelCol='Delay Duration',predictionCol='prediction')\n",
    "lin_reg = lin_reg.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([40.0, 45.0, -0.0, 60.0, 45.0, 90.0, 75.0, 30.0, -0.0, 80.0, 60.0, 60.0, 40.0, 80.0, 60.0, 60.0, 40.0, 60.0, 30.0, 30.0, 60.0, 60.0, 60.0, 60.0, -0.0, 120.0, 60.0, 60.0, 60.0, -0.0, 60.0, -0.0, -0.0, 120.0, 60.0, -0.0, 60.0, 120.0, -0.0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.658194722302727e-13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = lin_reg.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+\n",
      "|Independent Features|Delay Duration|          prediction|\n",
      "+--------------------+--------------+--------------------+\n",
      "|     (39,[23],[1.0])|          60.0|  60.000000000000014|\n",
      "|      (39,[7],[1.0])|          60.0|  30.000000000000004|\n",
      "|      (39,[1],[1.0])|         120.0|   45.00000000000001|\n",
      "|     (39,[14],[1.0])|         120.0|   60.00000000000001|\n",
      "|     (39,[25],[1.0])|           0.0|  120.00000000000006|\n",
      "|      (39,[3],[1.0])|          60.0|   60.00000000000002|\n",
      "|      (39,[3],[1.0])|          60.0|   60.00000000000002|\n",
      "|      (39,[5],[1.0])|         120.0|   90.00000000000001|\n",
      "|      (39,[7],[1.0])|          60.0|  30.000000000000004|\n",
      "|      (39,[5],[1.0])|         120.0|   90.00000000000001|\n",
      "|     (39,[10],[1.0])|         120.0|   60.00000000000001|\n",
      "|     (39,[17],[1.0])|           0.0|  60.000000000000014|\n",
      "|      (39,[2],[1.0])|         120.0|-5.04870979341447...|\n",
      "+--------------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize the model over the training set\n",
    "trainingSummary = lin_reg.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.307692307692314\n",
      "61.28433103795155\n",
      "-1.0035511363636371\n"
     ]
    }
   ],
   "source": [
    "#Some probability calculations\n",
    "\n",
    "print(pred_results.meanAbsoluteError)\n",
    "print(pred_results.rootMeanSquaredError)\n",
    "print(pred_results.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Vizualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "beta = np.sort(lin_reg.coefficients)\n",
    "plt.plot(beta)\n",
    "plt.ylabel('Beta Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
