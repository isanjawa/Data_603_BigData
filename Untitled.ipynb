{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: py4j==0.10.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyspark==2.3.2) (0.10.7)\n",
      "Requirement already satisfied: pymongo in c:\\programdata\\anaconda3\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: pymongo[srv] in c:\\programdata\\anaconda3\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: dnspython<2.0.0,>=1.16.0; extra == \"srv\" in c:\\programdata\\anaconda3\\lib\\site-packages (from pymongo[srv]) (1.16.0)\n",
      "Requirement already satisfied: dnspython in c:\\programdata\\anaconda3\\lib\\site-packages (1.16.0)\n",
      "Requirement already satisfied: pymongo[tls] in c:\\programdata\\anaconda3\\lib\\site-packages (3.10.1)\n"
     ]
    }
   ],
   "source": [
    "# Installing packages\n",
    "!pip install pyspark==2.3.2\n",
    "!pip install pymongo\n",
    "!pip install pymongo[srv]\n",
    "!pip install dnspython\n",
    "!pip install pymongo[tls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Classes\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark_session = SparkSession \\\n",
    "#     .builder \\\n",
    "#     .appName(\"mongo\") \\\n",
    "#     .config(\"spark.mongodb.input.uri=mongodb://127.0.0.1/Player_db.playerInfo\") \\\n",
    "#     .config(\"spark.mongodb.output.uri=mongodb://127.0.0.1/Player_db.playerInfo\") \\\n",
    "#     .config('spark.driver.extraClassPath', 'jars/*') \\\n",
    "#     .getOrCreate()\n",
    "# df_players = spark_session.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "# df_players.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
